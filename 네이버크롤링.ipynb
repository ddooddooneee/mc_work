{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 코드 개요\n",
    "1. 크롤링 사이트 : 네이버쇼핑 - 네이버 페이탭\n",
    "2. 크롤링 데이터 : 상품명, url\n",
    "3. 1페이지부터 20페이지까지 순회하며 url 및 상품명 수집"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 주요 모듈 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "from urllib.parse import quote\n",
    "import chromedriver_autoinstaller\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## depth2(계절가전), depth3(에어컨) 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_name = ['계절가전','에어컨']\n",
    "    # 파일 저장에 사용\n",
    "urls = ['https://search.shopping.naver.com/search/category/100000581','https://search.shopping.naver.com/search/category/100000620#']\n",
    "    # depth2와 depth3의 페이지 링크 포함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 계절가전 --------------------\n",
      "page_nums: 1 수집 개수: 40\n",
      "page_nums: 2 수집 개수: 80\n",
      "page_nums: 3 수집 개수: 120\n",
      "page_nums: 4 수집 개수: 160\n",
      "page_nums: 5 수집 개수: 200\n",
      "page_nums: 6 수집 개수: 240\n",
      "page_nums: 7 수집 개수: 280\n",
      "page_nums: 8 수집 개수: 320\n",
      "page_nums: 9 수집 개수: 360\n",
      "page_nums: 10 수집 개수: 400\n",
      "page_nums: 11 수집 개수: 440\n",
      "page_nums: 12 수집 개수: 480\n",
      "page_nums: 13 수집 개수: 520\n",
      "page_nums: 14 수집 개수: 560\n",
      "page_nums: 15 수집 개수: 600\n",
      "page_nums: 16 수집 개수: 640\n",
      "page_nums: 17 수집 개수: 680\n",
      "page_nums: 18 수집 개수: 720\n",
      "page_nums: 19 수집 개수: 760\n",
      "-------------------- 에어컨 --------------------\n",
      "page_nums: 1 수집 개수: 40\n",
      "page_nums: 2 수집 개수: 80\n",
      "page_nums: 3 수집 개수: 120\n",
      "page_nums: 4 수집 개수: 160\n",
      "page_nums: 5 수집 개수: 200\n",
      "page_nums: 6 수집 개수: 240\n",
      "page_nums: 7 수집 개수: 280\n",
      "page_nums: 8 수집 개수: 320\n",
      "page_nums: 9 수집 개수: 360\n",
      "page_nums: 10 수집 개수: 400\n",
      "page_nums: 11 수집 개수: 440\n",
      "page_nums: 12 수집 개수: 480\n",
      "page_nums: 13 수집 개수: 520\n",
      "page_nums: 14 수집 개수: 560\n",
      "page_nums: 15 수집 개수: 600\n",
      "page_nums: 16 수집 개수: 640\n",
      "page_nums: 17 수집 개수: 680\n",
      "page_nums: 18 수집 개수: 720\n",
      "page_nums: 19 수집 개수: 760\n"
     ]
    }
   ],
   "source": [
    "# 20페이지까지 상품명, url 수집\n",
    "for i in range(2) :\n",
    "            # range(2) 대신 range(len(urls)) 사용해도 무방 <= url 리스트 안에 있는 url을 순회하며 페이지 크롤링 해오는 게 목적인 반복문\n",
    "    print(f\"{'-'*20} {cat_name[i]} {'-'*20}\")\n",
    "            # 현재 어떤 depth에서 수집하고 있는지 정보 표시\n",
    "    \n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    driver = webdriver.Chrome(service = Service(ChromeDriverManager().install()), options = chrome_options) # 크롬드라이버 자동 인스톨, 안되면 직접 설치 필요\n",
    "    #driver = webdriver.Chrome(service = Service('C:/Users/user/Desktop/작업용 폴더/chromedriver-win64/chromedriver-win64/chromedriver.exe'), options = chrome_options)\n",
    "    driver.get(urls[i]) \n",
    "            # 계절가전, 에어컨 url 접근\n",
    "\n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    # 네이버 페이 클릭\n",
    "    driver.find_element(By.XPATH, '//*[@id=\"content\"]/div[1]/div[1]/ul/li[3]/a').click()\n",
    "                                        # [네이버페이] 탭의 XPATH 값\n",
    "    \n",
    "    time.sleep(0.5)\n",
    "    page_nums = 1\n",
    "    prod_df = pd.DataFrame(columns = ['상품명','url'])\n",
    "                # 상품명, url 두 열을 가지고 있는 데이터 프레임 완성\n",
    "    while 1 :\n",
    "            # while 1(True) : 무한 반복문 처리\n",
    "        if page_nums == 21 :\n",
    "            # 20페이지까지만 크롤링\n",
    "            break\n",
    "            \n",
    "        SCROLL_PAUSE_SEC = 1\n",
    "\n",
    "        # 스크롤 높이 가져옴\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "        while 1:\n",
    "            # 끝까지 스크롤 다운 - 네이버 쇼핑 페이지가 스크롤을 내려야 추가정보를 가져오는 형태로 구성되어 있음\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            ''' \n",
    "            execute_script(\"스크립트\", 요소) : 해당 페이지에 스크립트를 만들 때 사용.\n",
    "                                                요소가 필수 파라미터는 아니나, 요소가 있으면 요소에 스크립트가 실행되고 없으면 전체페이지에 스크립트가 실행\n",
    "            '''\n",
    "\n",
    "            # 1초 대기\n",
    "            time.sleep(SCROLL_PAUSE_SEC)\n",
    "\n",
    "            # 스크롤 다운 후 스크롤 높이 다시 가져옴\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "                    # 더이상 스크롤이 내려가지 않을때까지 해당 루틴 반복 & 반복문 중지\n",
    "            last_height = new_height\n",
    "        time.sleep(1)\n",
    "        soup = BeautifulSoup(driver.page_source,'html.parser')\n",
    "\n",
    "        prod_list = soup.find_all('div',class_= 'product_title__Mmw2K')\n",
    "                                                    # 페이지에 있는 상품에 대한 정보 리스트 추출\n",
    "        for prod in prod_list :\n",
    "            url = str(prod).split('href=\"')[1].split()[0]\n",
    "                    # url 파서 중에서 'href=' 이후에 있는 부분만 추출\n",
    "            prod_nm = str(prod).split('title=')[1].split('>')[0].replace('\"','')\n",
    "                    # 상품명 파서 중에서 1) 'title='이후에 있는 부분 추출 2) '>' 앞에 있는 부분만 추출 3) 남은 \"부분 제거\n",
    "            new_df = pd.DataFrame([[prod_nm,url]],columns = ['상품명','url'])\n",
    "                    # 데이터프레임에 상품명과 url 값 입력\n",
    "            prod_df = pd.concat([prod_df,new_df])\n",
    "\n",
    "        \n",
    "        page_nums += 1\n",
    "        if page_nums == 21 :\n",
    "            break\n",
    "            # 20페이지까지만 해당 코드 반복\n",
    "        elif page_nums-1 == 1 :\n",
    "            driver.find_element(By.XPATH,'//*[@id=\"content\"]/div[1]/div[4]/a').click()\n",
    "                                                # 다음 클릭\n",
    "        else :\n",
    "            driver.find_element(By.XPATH,'//*[@id=\"content\"]/div[1]/div[4]/a[2]').click()\n",
    "                                                # 다음 클릭\n",
    "        time.sleep(1)\n",
    "        print('page_nums:', page_nums-1, '수집 개수:',len(prod_df))\n",
    "\n",
    "    prod_df = prod_df.reset_index(drop = True)\n",
    "    file_name = f'{cat_name[i]}(네이버페이,800개).csv'\n",
    "    prod_df.to_csv(file_name, index = False, encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## depth4 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_crawl():\n",
    "    page_nums = 1\n",
    "    prod_df = pd.DataFrame( columns = ['상품명', 'url'])\n",
    "\n",
    "    while 1: \n",
    "        if page_nums == 21:\n",
    "            break \n",
    "                # 20페이지까지만 크롤링 코드 반복\n",
    "\n",
    "        SCROLL_PAUSE_SEC = 1\n",
    "\n",
    "        # 스크롤 높이 \n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "        while 1:\n",
    "            # 끝까지 스크롤 다운\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "            time.sleep(SCROLL_PAUSE_SEC)\n",
    "\n",
    "            # 스크롤 다운 후 스크롤 높이 다시 가져옴\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "            last_height = new_height\n",
    "        time.sleep(1)\n",
    "\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "        prod_list = soup.find_all('div', class_='product_title_Mmw2K')\n",
    "        for prod in prod_list:\n",
    "            url = str(prod).split('href=\"')[1].split()[0]\n",
    "            prod_nm = str(prod).split('title=')[1].split('>')[0].replace('\"','')\n",
    "            new_df = pd.DataFrame([[prod_nm, url]], columns = ['상품명', 'url'])\n",
    "            prod_df = pd.concat([prod_df, new_df])\n",
    "\n",
    "        page_nums += 1\n",
    "        if page_nums == 21 :\n",
    "            break\n",
    "        elif page_nums-1 == 1 :\n",
    "            driver.find_element(By.XPATH, '//*[@id=\"content\"]/div[1]/div[4]/a').click()\n",
    "        else :\n",
    "            driver.find_element(By.XPATH,'//*[@id=\"content\"]/div[1]/div[4]/a[2]').click()\n",
    "        time.sleep(1)\n",
    "\n",
    "        print('page nums:', page_nums-1, '수집개수 :', len(prod_df))\n",
    "\n",
    "    return prod_df\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //*[@id=\"container\"]/div/div[2]/div[1]/div[1]/div[2]/div/ul\n",
    "# //*[@id=\"container\"]/div/div[2]/div[1]/div[1]/div[2]/div/ul/li[1]/a/span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 벽걸이형 --------------------\n",
      "page nums: 1 수집개수 : 0\n",
      "page nums: 2 수집개수 : 0\n",
      "page nums: 3 수집개수 : 0\n",
      "page nums: 4 수집개수 : 0\n",
      "page nums: 5 수집개수 : 0\n",
      "page nums: 6 수집개수 : 0\n",
      "page nums: 7 수집개수 : 0\n",
      "page nums: 8 수집개수 : 0\n",
      "page nums: 9 수집개수 : 0\n",
      "page nums: 10 수집개수 : 0\n",
      "page nums: 11 수집개수 : 0\n",
      "page nums: 12 수집개수 : 0\n",
      "page nums: 13 수집개수 : 0\n",
      "page nums: 14 수집개수 : 0\n",
      "page nums: 15 수집개수 : 0\n",
      "page nums: 16 수집개수 : 0\n",
      "page nums: 17 수집개수 : 0\n",
      "page nums: 18 수집개수 : 0\n",
      "page nums: 19 수집개수 : 0\n",
      "-------------------- 스탠드형 --------------------\n",
      "page nums: 1 수집개수 : 0\n",
      "page nums: 2 수집개수 : 0\n",
      "page nums: 3 수집개수 : 0\n",
      "page nums: 4 수집개수 : 0\n",
      "page nums: 5 수집개수 : 0\n",
      "page nums: 6 수집개수 : 0\n",
      "page nums: 7 수집개수 : 0\n",
      "page nums: 8 수집개수 : 0\n",
      "page nums: 9 수집개수 : 0\n",
      "page nums: 10 수집개수 : 0\n",
      "page nums: 11 수집개수 : 0\n",
      "page nums: 12 수집개수 : 0\n",
      "page nums: 13 수집개수 : 0\n",
      "page nums: 14 수집개수 : 0\n",
      "page nums: 15 수집개수 : 0\n",
      "page nums: 16 수집개수 : 0\n",
      "page nums: 17 수집개수 : 0\n",
      "page nums: 18 수집개수 : 0\n",
      "page nums: 19 수집개수 : 0\n",
      "-------------------- 멀티형 --------------------\n",
      "page nums: 1 수집개수 : 0\n",
      "page nums: 2 수집개수 : 0\n",
      "page nums: 3 수집개수 : 0\n",
      "page nums: 4 수집개수 : 0\n",
      "page nums: 5 수집개수 : 0\n",
      "page nums: 6 수집개수 : 0\n",
      "page nums: 7 수집개수 : 0\n",
      "page nums: 8 수집개수 : 0\n",
      "page nums: 9 수집개수 : 0\n",
      "page nums: 10 수집개수 : 0\n",
      "page nums: 11 수집개수 : 0\n",
      "page nums: 12 수집개수 : 0\n",
      "page nums: 13 수집개수 : 0\n",
      "page nums: 14 수집개수 : 0\n",
      "page nums: 15 수집개수 : 0\n",
      "page nums: 16 수집개수 : 0\n",
      "page nums: 17 수집개수 : 0\n",
      "page nums: 18 수집개수 : 0\n",
      "page nums: 19 수집개수 : 0\n",
      "-------------------- 천장형 --------------------\n",
      "page nums: 1 수집개수 : 0\n",
      "page nums: 2 수집개수 : 0\n",
      "page nums: 3 수집개수 : 0\n",
      "page nums: 4 수집개수 : 0\n",
      "page nums: 5 수집개수 : 0\n",
      "page nums: 6 수집개수 : 0\n",
      "page nums: 7 수집개수 : 0\n",
      "page nums: 8 수집개수 : 0\n",
      "page nums: 9 수집개수 : 0\n",
      "page nums: 10 수집개수 : 0\n",
      "page nums: 11 수집개수 : 0\n",
      "page nums: 12 수집개수 : 0\n",
      "page nums: 13 수집개수 : 0\n",
      "page nums: 14 수집개수 : 0\n",
      "page nums: 15 수집개수 : 0\n",
      "page nums: 16 수집개수 : 0\n",
      "page nums: 17 수집개수 : 0\n",
      "page nums: 18 수집개수 : 0\n",
      "page nums: 19 수집개수 : 0\n",
      "-------------------- 시스템 --------------------\n",
      "page nums: 1 수집개수 : 0\n",
      "page nums: 2 수집개수 : 0\n",
      "page nums: 3 수집개수 : 0\n",
      "page nums: 4 수집개수 : 0\n",
      "page nums: 5 수집개수 : 0\n",
      "page nums: 6 수집개수 : 0\n",
      "page nums: 7 수집개수 : 0\n",
      "page nums: 8 수집개수 : 0\n",
      "page nums: 9 수집개수 : 0\n",
      "page nums: 10 수집개수 : 0\n",
      "page nums: 11 수집개수 : 0\n",
      "page nums: 12 수집개수 : 0\n",
      "page nums: 13 수집개수 : 0\n",
      "page nums: 14 수집개수 : 0\n",
      "page nums: 15 수집개수 : 0\n",
      "page nums: 16 수집개수 : 0\n",
      "page nums: 17 수집개수 : 0\n",
      "page nums: 18 수집개수 : 0\n",
      "page nums: 19 수집개수 : 0\n",
      "-------------------- 냉온풍기 --------------------\n",
      "page nums: 1 수집개수 : 0\n",
      "page nums: 2 수집개수 : 0\n",
      "page nums: 3 수집개수 : 0\n",
      "page nums: 4 수집개수 : 0\n",
      "page nums: 5 수집개수 : 0\n",
      "page nums: 6 수집개수 : 0\n",
      "page nums: 7 수집개수 : 0\n",
      "page nums: 8 수집개수 : 0\n",
      "page nums: 9 수집개수 : 0\n",
      "page nums: 10 수집개수 : 0\n",
      "page nums: 11 수집개수 : 0\n",
      "page nums: 12 수집개수 : 0\n",
      "page nums: 13 수집개수 : 0\n",
      "page nums: 14 수집개수 : 0\n",
      "page nums: 15 수집개수 : 0\n",
      "page nums: 16 수집개수 : 0\n",
      "page nums: 17 수집개수 : 0\n",
      "page nums: 18 수집개수 : 0\n",
      "page nums: 19 수집개수 : 0\n",
      "-------------------- 창문형 --------------------\n",
      "page nums: 1 수집개수 : 0\n",
      "page nums: 2 수집개수 : 0\n",
      "page nums: 3 수집개수 : 0\n",
      "page nums: 4 수집개수 : 0\n",
      "page nums: 5 수집개수 : 0\n",
      "page nums: 6 수집개수 : 0\n",
      "page nums: 7 수집개수 : 0\n",
      "page nums: 8 수집개수 : 0\n",
      "page nums: 9 수집개수 : 0\n",
      "page nums: 10 수집개수 : 0\n",
      "page nums: 11 수집개수 : 0\n",
      "page nums: 12 수집개수 : 0\n",
      "page nums: 13 수집개수 : 0\n",
      "page nums: 14 수집개수 : 0\n",
      "page nums: 15 수집개수 : 0\n",
      "page nums: 16 수집개수 : 0\n",
      "page nums: 17 수집개수 : 0\n",
      "page nums: 18 수집개수 : 0\n",
      "page nums: 19 수집개수 : 0\n",
      "-------------------- 이동식 --------------------\n",
      "page nums: 1 수집개수 : 0\n",
      "page nums: 2 수집개수 : 0\n",
      "page nums: 3 수집개수 : 0\n",
      "page nums: 4 수집개수 : 0\n",
      "page nums: 5 수집개수 : 0\n",
      "page nums: 6 수집개수 : 0\n",
      "page nums: 7 수집개수 : 0\n",
      "page nums: 8 수집개수 : 0\n",
      "page nums: 9 수집개수 : 0\n",
      "page nums: 10 수집개수 : 0\n",
      "page nums: 11 수집개수 : 0\n",
      "page nums: 12 수집개수 : 0\n",
      "page nums: 13 수집개수 : 0\n",
      "page nums: 14 수집개수 : 0\n",
      "page nums: 15 수집개수 : 0\n",
      "page nums: 16 수집개수 : 0\n",
      "page nums: 17 수집개수 : 0\n",
      "page nums: 18 수집개수 : 0\n",
      "page nums: 19 수집개수 : 0\n",
      "-------------------- 실외기 --------------------\n",
      "page nums: 1 수집개수 : 0\n",
      "page nums: 2 수집개수 : 0\n",
      "page nums: 3 수집개수 : 0\n",
      "page nums: 4 수집개수 : 0\n",
      "page nums: 5 수집개수 : 0\n",
      "page nums: 6 수집개수 : 0\n",
      "page nums: 7 수집개수 : 0\n",
      "page nums: 8 수집개수 : 0\n",
      "page nums: 9 수집개수 : 0\n",
      "page nums: 10 수집개수 : 0\n",
      "page nums: 11 수집개수 : 0\n",
      "page nums: 12 수집개수 : 0\n",
      "page nums: 13 수집개수 : 0\n",
      "page nums: 14 수집개수 : 0\n",
      "page nums: 15 수집개수 : 0\n",
      "page nums: 16 수집개수 : 0\n",
      "page nums: 17 수집개수 : 0\n",
      "page nums: 18 수집개수 : 0\n",
      "page nums: 19 수집개수 : 0\n",
      "-------------------- 리모컨, 주변용품 --------------------\n",
      "page nums: 1 수집개수 : 0\n",
      "page nums: 2 수집개수 : 0\n",
      "page nums: 3 수집개수 : 0\n",
      "page nums: 4 수집개수 : 0\n",
      "page nums: 5 수집개수 : 0\n",
      "page nums: 6 수집개수 : 0\n",
      "page nums: 7 수집개수 : 0\n",
      "page nums: 8 수집개수 : 0\n",
      "page nums: 9 수집개수 : 0\n",
      "page nums: 10 수집개수 : 0\n",
      "page nums: 11 수집개수 : 0\n",
      "page nums: 12 수집개수 : 0\n",
      "page nums: 13 수집개수 : 0\n",
      "page nums: 14 수집개수 : 0\n",
      "page nums: 15 수집개수 : 0\n",
      "page nums: 16 수집개수 : 0\n",
      "page nums: 17 수집개수 : 0\n",
      "page nums: 18 수집개수 : 0\n",
      "page nums: 19 수집개수 : 0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "url = 'https://search.shopping.naver.com/search/category/100000620?catId=50001421&origQuery&pagingIndex=1&pagingSize=40&productSet=total&query&sort=rel&timestamp=&viewType=list'\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "driver = webdriver.Chrome(service = Service(ChromeDriverManager().install()), options = chrome_options) # 크롬드라이버 자동 인스톨, 안되면 직접 설치 필요\n",
    "# driver = webdriver.Chrome(service = Service('C:/Users/user/Desktop/작업용 폴더/chromedriver-win64/chromedriver-win64/chromedriver.exe'), options = chrome_options)\n",
    "driver.get(url)\n",
    "cat_list = driver.find_element(By.XPATH,'//*[@id=\"container\"]/div/div[2]/div[1]/div[1]/div[2]/div/ul').text.split('\\n')\n",
    "                                    # 카테고리 리스트 추출\n",
    "for cat in driver.find_element(By.XPATH,'//*[@id=\"container\"]/div/div[2]/div[1]/div[1]/div[2]/div/ul').text.split('\\n') :\n",
    "    print(f\"{'-'*20} {cat} {'-'*20}\")\n",
    "    cat_idx = cat_list.index(cat)+1\n",
    "                    # cat_list에서 현재 반복중인 부분의 순서\n",
    "                        ## cat_list에서 0번째이면 cat_idx = 1\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    cat_xpath = f'//*[@id=\"container\"]/div/div[2]/div[1]/div[1]/div[2]/div/ul/li[{cat_idx}]/a' # 카테고리 클릭 \n",
    "                        # cat_idx = 1 이므로 li[1]번째 요소를 클릭\n",
    "    driver.find_element(By.XPATH, cat_xpath).click() \n",
    "    time.sleep(2)\n",
    "    driver.find_element(By.XPATH, '//*[@id=\"content\"]/div[1]/div[1]/ul/li[3]/a').click()\n",
    "                        # 네이버페이 탭 클릭\n",
    "    # driver.find_element(By.XPATH, '//*[@id=\"content\"]/div[1]/div[1]/div/div[2]/div[1]/a').click()\n",
    "    # time.sleep(0.3)\n",
    "    # driver.find_element(By.XPATH, '//*[@id=\"content\"]/div[1]/div[1]/div/div[2]/div[1]/div/ul/li[7]/a').click()\n",
    "    # time.sleep(1)\n",
    "    # for url_num in range(1,len(driver.find_element(By.XPATH,'//*[@id=\"content\"]/div[1]/div[1]/div/div[2]/div[1]/div/div[2]').text.split('\\n'))+1) :\n",
    "    #     checkbox_xpath = f'//*[@id=\"content\"]/div[1]/div[1]/div/div[2]/div[1]/div/div[2]/ul/li[{str(url_num)}]'\n",
    "    #     driver.find_element(By.XPATH, checkbox_xpath).click()\n",
    "    #     time.sleep(0.5)\n",
    "    # driver.find_element(By.XPATH,'//*[@id=\"content\"]/div[1]/div[1]/div/div[2]/div[1]/div/div[3]/a[1]').click()\n",
    "    # time.sleep(0.5)\n",
    "    # cat_xpath = f'//*[@id=\"container\"]/div/div[2]/div[1]/div[1]/div[2]/div/ul/li[{cat_idx}]/a'\n",
    "    # driver.find_element(By.XPATH, cat_xpath).click()\n",
    "    time.sleep(0.5)\n",
    "    prod_df = page_crawl()\n",
    "        # 해당 카테고리 내 20페이지까지 상품 크롤링\n",
    "    file_name = f'{cat}_URL(네이버페이, 800개).csv'\n",
    "    prod_df.to_csv(file_name,index = False, encoding = 'utf-8-sig')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
